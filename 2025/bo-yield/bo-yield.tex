\section{はじめに}

ある日、あなたは研究室のボスから次のように言われました。  
「このリストの中から、最も収率のよい反応条件を探してくれ」と。

リストに載っている反応の数が10件程度であれば、すべてを試してみることも現実的かもしれません。  
しかし、それが数百件、数千件にも及ぶとなると話は別です。

化学反応には、温度・溶媒・触媒など、数多くの条件が関わります。  
それらの組み合わせをすべて網羅的に試すことは現実的ではありません。  
そのため研究者は、限られた実験回数の中で、見込みのありそうな条件や未知の可能性を秘めた条件を優先的に試す必要があります。

こうした「次にどの実験を行うべきか」を効率的に決定するための手法のひとつが、\textbf{ベイズ最適化（Bayesian Optimization）}です。

\section{ベイズ最適化とは}

機械学習に親しみのある方であれば、ベイズ最適化をハイパーパラメータチューニングの手法として耳にしたことがあるかもしれません。  
ベイズ最適化とは、\textbf{評価にコストがかかるブラックボックス関数を、できるだけ少ない試行で最適化する手法}です。

ブラックボックス関数とは、入力に対して出力を得ることはできるものの、その内部構造や関数形が不明な関数を指します。  
例えば化学反応の収率は、温度・溶媒・触媒など多様な条件に依存しますが、その関係は極めて複雑で、明示的な数式で表すことは困難です。

ベイズ最適化は、このようなブラックボックス関数の最適化において、少ない試行回数で最適解を探索するために用いられます。  
その流れは主に次の2つのステップから構成されます。

\begin{enumerate}
  \item \textbf{サロゲートモデルの構築}
  
  まず、既存のデータをもとにブラックボックス関数を近似する「サロゲートモデル」を構築します。  
  一般的には、\textbf{ガウス過程回帰（Gaussian Process Regression, GPR）}が用いられます。  
  GPRは入力空間における関数の振る舞いを確率的にモデル化し、予測値とその不確実性を同時に推定することが可能です。  
  予測値に加えて不確実性も考慮することで、未知領域を探索する指針を得ることができます。

  \item \textbf{獲得関数の最適化}
  
  次に、サロゲートモデルの予測結果をもとに「次にどの点を評価すべきか」を決定します。  
  その判断に用いられるのが\textbf{獲得関数（Acquisition Function）}です。  
  獲得関数は、予測値と不確実性の両方を考慮しながら、探索（exploration）と活用（exploitation）のバランスをとって次の候補点を選びます。  
  代表的な獲得関数には、\textbf{EI（Expected Improvement）}、\textbf{PI（Probability of Improvement）}、\textbf{UCB（Upper Confidence Bound）}などがあります。
\end{enumerate}

この2つのステップを繰り返すことで、ベイズ最適化は徐々に最適解に近づいていきます。  
特に、評価コストが高い場合や探索空間が広い場合において、その効率性が際立ちます。  
実験コストが高く探索空間が膨大な\textbf{化学反応条件の最適化}は、まさにベイズ最適化が最も有効に機能する領域の一つです。

\section{従来のベイズ最適化の課題}

ベイズ最適化は少ない試行で最適解を見つける強力な手法ですが、その性能はサロゲートモデルの精度に大きく依存します。  
一般的なベイズ最適化では、探索開始時にはデータが少なく、サロゲートモデルは初期のわずかなデータから構築されます。  

そのため、探索初期においては予測精度が低く、効率的な探索が難しいという問題があります。  
また、サロゲートモデルは通常、各タスクごとに一から学習を行うため、過去の実験データや他の反応系で得られた知識を活用できません。

一方、化学反応の分野には既に膨大な反応データや論文情報が存在します。  
にもかかわらず、従来のベイズ最適化ではそれらを活用せず、「毎回ゼロから探索を始める」という非効率な枠組みにとどまっています。

\section{事前学習済みモデルをサロゲートとして活用する}

従来のベイズ最適化では、サロゲートモデルは都度学習されるのが一般的です。  
しかし、近年の機械学習分野──特に自然言語処理や画像認識──では、\textbf{事前学習済みモデル（pretrained model）}の活用が標準的なアプローチとなっています。  
大規模データから汎用的な表現を学習し、それを個別タスクに転移することで、データが少ない段階から高い性能を発揮できることが知られています。

一方、ベイズ最適化の分野では、こうした「事前知識をもつサロゲートモデル」を導入した研究はまだ限られています。  
多くの手法は、対象ごとにデータを収集し、\textit{その場で一からモデルを構築する}という前提に立っており、  
初期段階では予測性能が十分でないのが現状です。

化学反応の最適化の文脈では、すでに多くの反応データベースや文献情報が整備されています。  
これらを活用しないのは大きな機会損失といえます。  
そこで本研究では、\textbf{事前学習済みの反応予測モデル}をベイズ最適化のサロゲートとして活用する手法を検討しました。

その一例として、今回はTransformerアーキテクチャに基づく収率予測モデルである\textbf{ReactionT5}\cite{sagawa2025reactiont5}を用いました。  
ReactionT5は約18万件の反応データを学習しており、化学反応の収率を高精度に予測する能力を持ちます。  
また、ファインチューニングにより特定の反応系に適応させることも可能です。  
これをサロゲートモデルとして利用することで、未知の反応条件に対しても初期段階から一定の予測精度を確保し、より効率的な条件探索が可能になります。

\section{ReactionT5を用いたベイズ最適化の枠組み}

全体の流れは図\ref{fig:bo_rt5}に示すように、従来のベイズ最適化と同様の構造を持ちます。  
ただし、ReactionT5のようなTransformerベースの事前学習済みモデルを含め、一般的なニューラルネットワークは推論時に確率的な振る舞いを持たないため、そのままでは不確実性の推定を行うことができません。したがって、これを可能にするためにはいくつかの工夫が必要となります。  
その中で最も簡単な手法の一つが、\textbf{MC Dropout}\cite{gal2015dropout}による不確実性推定です。

MC Dropoutでは、推論時にもDropoutを有効化し、複数回の推論を行うことで予測の分布を得ます。  
この分布の分散を不確実性の尺度として扱うことで、近似的にベイズ推定を実現します。  
Dropoutさえ含まれていれば、既存のニューラルネットワークに容易に導入できる点も利点です。  
本研究では、ReactionT5にMC Dropoutを適用して不確実性を推定し、ベイズ最適化のサロゲートモデルとして活用しています。

\begin{figure}[H]
  \centering
  \resizebox{\textwidth}{!}{
  \begin{tikzpicture}[
    node distance=14mm,
    box/.style = {draw, rounded corners, align=center, minimum width=32mm, minimum height=8mm},
    >={Latex[length=2.5mm]}
  ]
  \node[box] (model) {\shortstack{モデル\\\footnotesize（ReactionT5）}};
  \node[box, right=of model] (uncert) {\shortstack{不確実性推定\\\footnotesize（MC Dropout）}};
  \node[box, right=of uncert] (acq) {\shortstack{獲得関数最適化\\\footnotesize（EI / UCB / PI）}};
  \node[box, right=of acq] (exp) {\shortstack{実験・評価\\\footnotesize（新データ取得）}};
  \draw[->] (model) -- (uncert);
  \draw[->] (uncert) -- (acq);
  \draw[->] (acq) -- (exp);
  \draw[->] (exp.north) to[out=60, in=120]
    node[above, align=center, pos=0.5] {\footnotesize モデル更新\\{\footnotesize（学習/微調整）}}
    (model.north);
  \end{tikzpicture}
  }
  \caption{ReactionT5を用いたベイズ最適化の全体フロー}
  \label{fig:bo_rt5}
\end{figure}

\section{実験設計}
ベイズ最適化の有効性を評価するためには、未知の実験空間において、限られた試行回数で最適条件を効率的に探索できるかどうかを確認する必要があります。
そのため本研究では、ReactionT5の学習に使用されていない反応データセットを用いて検証を行いました。
具体的には、表\ref{tab:datasets}に示す3つのデータセットを使用しました。

Suzuki-MiyauraおよびBuchwald-Hartwigのデータセットについては、元のデータから「完全格子」と呼ばれる、すべての条件組み合わせが網羅された部分のみを抽出して利用しました。
これにより、探索空間が明確に定義された状態で、ベイズ最適化がどの程度効率的に高収率条件を見つけられるかを評価できるようにしました。
\begin{table}[H]
  \centering
  \caption{使用データセットと条件の組み合わせ}
  \label{tab:datasets}
  \begin{tabularx}{\textwidth}{@{}l X@{}}
    \toprule
    データセット名 & 組み合わせ \\
    \midrule
    NiB & \(33\) substrates \(\times\) \(23\) ligands \(\times\) \(2\) solvents \(= \num{1518}\) entries \\
    Suzuki-Miyaura
        & \(4\) reactant\_1 \(\times\) \(3\) reactant\_2 \(\times\) \(1\) catalyst
          \(\times\) \(11\) ligands \(\times\) \(7\) reagents \(\times\) \(4\) solvents
          \(= \num{3696}\) entries \\
    Buchwald-Hartwig
        & \(2\) ligands \(\times\) \(22\) additives \(\times\) \(3\) bases \(\times\) \(15\) aryl halides
          \(= \num{1980}\) entries \\
    \bottomrule
  \end{tabularx}
\end{table}

事前学習済みモデルとして、ReactionT5の収率予測モデルを使用しました。
このモデルに対してMC Dropoutを適用することで、予測値に加えてその不確実性も推定できるようにしました。
MC Dropoutの設定としては、ドロップアウト率をデフォルトの0.1に設定し、推論時に10回のサンプリングを行いました。

ファインチューニングは、探索を10回行うごとに実施し、それまでに得られた実験データを用いてモデルを更新しました。
得られたデータが25件以上となった場合には、学習データとテストデータを8:2の割合で分割し、テストデータにおける予測性能を確認しました。
ファインチューニングの設定は以下の通りです。

\begin{itemize}
  \item エポック数: 2
  \item 訓練バッチサイズ: 8
  \item 評価バッチサイズ: 16
  \item 学習率: \(1 \times 10^{-4}\)
  \item 最適化手法: AdamW
  \item Weight Decay: \(1 \times 10^{-2}\)
\end{itemize}
ベイズ最適化の獲得関数としては、Expected Improvement（EI）を採用しました。
通常のベイズ最適化では初期点をランダムに選択しますが、本研究では事前学習済みモデルを利用しているため、初期点もReactionT5の予測結果に基づいて選択しました。

また、比較対象として、OptunaのTPE（Tree-structured Parzen Estimator）Samplerを用いた手法と、RDKitから取得したMorgan Fingerprintを特徴量に用いたガウス過程回帰（GPR）ベースの手法を実装しました。

ベイズ最適化は確率的な手法であるため、それぞれの手法とデータセットに対して、シード値を変えて5回ずつ実験を行いました。

\section{結果}
NiB、Suzuki-Miyaura、およびBuchwald-Hartwigの各データセットに対するベイズ最適化の結果を図\ref{fig:results}に示します。
各グラフでは、横軸に試行回数、縦軸にこれまでに得られた最高収率をプロットしています。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{bo-yield/img/results.png} 
  \caption{各データセットにおけるベイズ最適化の結果}
  \label{fig:results}
\end{figure}

図\ref{fig:results}から、ReactionT5を用いたベイズ最適化が必ずしもすべてのデータセットで最良の性能を示すわけではないことがわかります。
NiBデータセットでは、ReactionT5ベースの手法は他の手法と比較して収束が遅く、最終的な最高収率も低い傾向を示しました。
一方、Suzuki-MiyauraおよびBuchwald-Hartwigデータセットにおいては、ReactionT5ベースの手法が他の手法を上回る性能を示し、より効率的に高収率条件を探索できていることが確認されます。

\section{考察}
図\ref{fig:results}の結果から、ReactionT5をサロゲートモデルとして用いたベイズ最適化は、従来手法と比較してデータセットによって挙動が異なることが確認されました。

まず、NiBデータセットにおいては、ReactionT5ベースの手法は他の手法に比べて収束が遅く、最終的な最高収率も低い傾向を示しました。
この要因として、NiBデータセットが他のデータセットに比べて化学構造や反応条件の多様性が高く、ReactionT5の事前学習時に十分に類似する反応が含まれていなかった可能性が考えられます。
すなわち、事前学習済みモデルに内在する「化学的事前知識」が、必ずしも未知の反応空間に対して有効に転移しない場合があることを示唆しています。

一方、Suzuki-MiyauraおよびBuchwald-Hartwigデータセットでは、ReactionT5ベースの手法がGPRベースおよびOptuna TPEを上回る性能を示しました。
これらのデータセットは、比較的均質な反応系から構成されており、事前学習済みモデルが学習している反応パターンと親和性が高かったと考えられます。
その結果、初期段階から高い予測精度を発揮し、少ない試行回数で高収率条件を見出すことができたと解釈できます。

総じて、本手法は「事前知識を有するサロゲートモデル」を導入することで、特定の反応系における探索効率を改善できる可能性を示しました。
一方で、NiBのように事前知識と対象系の分布が大きく異なる場合には、事前学習のバイアスが探索効率を損なうリスクもあるため、
モデルの適用範囲や、事前学習に用いるデータの選定方針が今後の課題として挙げられます。

\section{おわりに}
最後に、より大きな展望として「人間と道具」の関係について考えてみたいと思います。
この問題を考える上で外せない哲学者の一人に、ハイデガーがいます。
ハイデガーは、道具を含むあらゆる存在を「目的のために作られ、使われるもの」としての道具的連関から切り離し、
存在そのもののあり方として捉え直そうとしました。
この試みは、道具や自然を単なる客体的な利用の対象から解放し、
人間と世界との関わりそのものを見つめ直そうとするものでした。
しかしその過程で、人間と道具が協働し、「目的のために共に何かをなす」という、
本来あったはずの目的的な関係までもが、見えにくくなってしまったように思えます。

たとえば、職人にとっての道具は、単に同じ機能を備えていればよいというものではありません。
長年使い込まれた道具は、職人の身体の一部のように馴染み、
手の感覚や動きと一体化して初めて、最高の成果を発揮します。
そこには、単なる主体と客体の関係を超えた、相互に影響を及ぼし合う協働的な関係があります。
このように、人間と道具、さらには自然を含むあらゆる存在が互いに関わり合いながら、
共に目的を実現していく関係性を再構築することが、これからの科学技術にとって重要ではないでしょうか。

「事実から当為は導けない」というのは、広く共有された命題の一つです。
しかし、時として事実は、いかなる言葉よりも雄弁に当為を語り得ます。
もし、これからの科学技術研究に意義があるとするならば、それは実生活上の利益を超えて、
私たちが当然のものとして受け入れてきた主体と客体、人間と自然といった二項対立的な関係を問い直し、
新たな協働のあり方を模索することにあるのではないでしょうか。

本稿で取り上げたベイズ最適化のような手法や、あるいはAI技術全般が、
そのような新たな関係性の構築に寄与することを願っています。

今回の研究は、京都大学医学研究科・小島諒介先生のご指導のもとに実施しました。
本研究で使用した実験データおよびソースコードは、以下のGitHubリポジトリにて公開しています。

\begin{itemize}
  \item \url{https://github.com/kazumasa-okamoto/ReactionT5-bo-yield}
\end{itemize}
